{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a954a8",
   "metadata": {},
   "source": [
    "# Биоинформатический анализ генома: поиск и предсказание генов\n",
    "\n",
    "Этот notebook демонстрирует основные методы работы с геномными данными:\n",
    "1. Загрузка и парсинг геномных файлов (FASTA, GFF)\n",
    "2. Поиск открытых рамок считывания (ORF)\n",
    "3. Сравнение предсказанных генов с референсными данными\n",
    "4. Оценка качества предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160448f3",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 1: ЗАГРУЗКА ДАННЫХ E.COLI\n",
    "\n",
    "Загружаем референсный геном кишечной палочки E.coli strain K-12 - один из наиболее изученных бактериальных геномов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Загрузка генома E.coli ===\")\n",
    "print(\"Скачиваем референсный геном кишечной палочки E.coli strain K-12\")\n",
    "print(\"Это один из наиболее изученных бактериальных геномов\")\n",
    "\n",
    "# Загружаем сжатый геном E.coli\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.fna.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем размер скачанного файла\n",
    "!ls -hlrt\n",
    "\n",
    "print(\"\\nРаспаковываем геном...\")\n",
    "# Распаковываем архив\n",
    "!gzip -d GCF_000005845.2_ASM584v2_genomic.fna.gz\n",
    "\n",
    "# Проверяем размер распакованного файла\n",
    "!ls -hlrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nПросматриваем начало файла:\")\n",
    "print(\"FASTA формат содержит:\")\n",
    "print(\"- Заголовок, начинающийся с '>'\")\n",
    "print(\"- Последовательность ДНК в стандартных символах (A, T, G, C)\")\n",
    "\n",
    "# Смотрим первые 10 строк генома\n",
    "!head GCF_000005845.2_ASM584v2_genomic.fna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c9977f",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 2: ПАРСИНГ FASTA ФАЙЛА\n",
    "\n",
    "Создаем функцию для чтения FASTA формата и загружаем геномную последовательность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Парсинг FASTA файла ===\")\n",
    "print(\"Создаем функцию для чтения FASTA формата\")\n",
    "\n",
    "def parse_fasta(filepath):\n",
    "    \"\"\"\n",
    "    Парсит FASTA файл и возвращает пары (заголовок, последовательность)\n",
    "    \n",
    "    FASTA формат:\n",
    "    >Заголовок_последовательности\n",
    "    ATGCGATCGATCG...\n",
    "    ATCGATCGATCGA...\n",
    "    \n",
    "    Args:\n",
    "        filepath: путь к FASTA файлу\n",
    "    \n",
    "    Yields:\n",
    "        tuple: (заголовок, последовательность)\n",
    "    \"\"\"\n",
    "    header = None\n",
    "    sequence_lines = []\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Удаляем пробелы и символы новой строки\n",
    "            if not line:\n",
    "                continue  # Пропускаем пустые строки\n",
    "            if line.startswith('>'):\n",
    "                if header is not None:\n",
    "                    # Если уже есть заголовок, возвращаем предыдущую последовательность\n",
    "                    yield header, ''.join(sequence_lines)\n",
    "                header = line[1:]  # Убираем '>' в начале\n",
    "                sequence_lines = []  # Сброс буфера для новой последовательности\n",
    "            else:\n",
    "                sequence_lines.append(line)\n",
    "\n",
    "        # Возвращаем последнюю последовательность в файле\n",
    "        if header is not None:\n",
    "            yield header, ''.join(sequence_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем парсер к нашему файлу\n",
    "fasta_path = \"GCF_000005845.2_ASM584v2_genomic.fna\"\n",
    "\n",
    "print(\"Анализируем структуру FASTA файла:\")\n",
    "for header, sequence in parse_fasta(fasta_path):\n",
    "    print(\"Header:\", header)\n",
    "    print(\"Sequence length:\", len(sequence), \"nucleotides\")\n",
    "    print(\"First 60 characters:\", sequence[:60] + '...')\n",
    "    \n",
    "    # Сохраняем последовательность для дальнейшего анализа\n",
    "    genome_sequence = sequence\n",
    "    break  # E.coli имеет одну хромосому, поэтому берем первую\n",
    "\n",
    "print(f\"\\nПолная длина генома E.coli: {len(genome_sequence):,} нуклеотидов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0227ee",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 3: БАЗОВЫЕ ОПЕРАЦИИ С ДНК\n",
    "\n",
    "ДНК двуцепочечная, и гены могут находиться на любой из цепей. Для анализа противоположной цепи нужно вычислить обратную комплементарную последовательность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fcbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Базовые операции с ДНК ===\")\n",
    "\n",
    "def reverse_complement(dna_seq):\n",
    "    \"\"\"\n",
    "    Вычисляет обратную комплементарную последовательность ДНК\n",
    "    \n",
    "    ДНК двуцепочечная, и гены могут находиться на любой из цепей.\n",
    "    Для анализа противоположной цепи нужно:\n",
    "    1. Заменить каждый нуклеотид на комплементарный (A↔T, G↔C)\n",
    "    2. Обратить последовательность (читать справа налево)\n",
    "    \n",
    "    Args:\n",
    "        dna_seq: последовательность ДНК\n",
    "    \n",
    "    Returns:\n",
    "        str: обратная комплементарная последовательность\n",
    "    \"\"\"\n",
    "    complement = {\n",
    "        'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G',\n",
    "        'a': 't', 't': 'a', 'g': 'c', 'c': 'g',\n",
    "        'N': 'N', 'n': 'n'  # N обозначает неопределенный нуклеотид\n",
    "    }\n",
    "    reversed_seq = dna_seq[::-1]  # Обращаем последовательность\n",
    "    rev_comp = ''.join(complement.get(base, base) for base in reversed_seq)\n",
    "    return rev_comp\n",
    "\n",
    "# Демонстрируем работу функции\n",
    "test_seq = \"ATGCGATCG\"\n",
    "print(f\"Исходная последовательность: {test_seq}\")\n",
    "print(f\"Обратная комплементарная:    {reverse_complement(test_seq)}\")\n",
    "\n",
    "print(f\"\\nДлина генома: {len(genome_sequence):,} п.н.\")\n",
    "\n",
    "# Создаем обратную комплементарную последовательность для анализа минус-цепи\n",
    "rev_comp_sequence = reverse_complement(genome_sequence)\n",
    "print(\"Обратная комплементарная последовательность создана\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa886bbd",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 4: ПОИСК СТАРТОВЫХ КОДОНОВ\n",
    "\n",
    "В бактериях гены обычно начинаются со стартового кодона ATG (метионин). Анализируем их распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Анализ стартовых кодонов ===\")\n",
    "print(\"В бактериях гены обычно начинаются со стартового кодона ATG (метионин)\")\n",
    "\n",
    "# Подсчитываем стартовые кодоны на обеих цепях\n",
    "methionine_start = \"ATG\"\n",
    "methionine_start_rc = \"CAT\"  # ATG на обратной цепи выглядит как CAT на прямой\n",
    "\n",
    "hits_plus = genome_sequence.count(methionine_start)\n",
    "hits_minus = genome_sequence.count(methionine_start_rc)\n",
    "\n",
    "print(f\"Стартовые кодоны ATG на плюс-цепи:  {hits_plus:,}\")\n",
    "print(f\"Стартовые кодоны ATG на минус-цепи: {hits_minus:,}\")\n",
    "print(f\"Общее количество ATG:              {hits_plus + hits_minus:,}\")\n",
    "\n",
    "print(f\"\\nЧастота ATG: {(hits_plus + hits_minus) / len(genome_sequence) * 1000:.2f} на 1000 п.н.\")\n",
    "print(\"Это примерно соответствует случайному распределению (ожидаемая частота ATG = 1/64 ≈ 0.016)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394a0a4",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 5: ЗАГРУЗКА АННОТАЦИИ ГЕНОВ (GFF)\n",
    "\n",
    "GFF (General Feature Format) содержит координаты и описания генов - эталонные данные для сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Загрузка аннотации генов ===\")\n",
    "print(\"GFF (General Feature Format) содержит координаты и описания генов\")\n",
    "\n",
    "# Загружаем GFF файл с аннотацией E.coli\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gz\n",
    "\n",
    "# Распаковываем\n",
    "!gzip -d GCF_000005845.2_ASM584v2_genomic.gff.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nПросматриваем структуру GFF файла:\")\n",
    "print(\"GFF содержит 9 колонок:\")\n",
    "print(\"1. Хромосома/контиг\")\n",
    "print(\"2. Источник аннотации\") \n",
    "print(\"3. Тип элемента (gene, CDS, etc.)\")\n",
    "print(\"4. Начало (1-based)\")\n",
    "print(\"5. Конец (включительно)\")\n",
    "print(\"6. Скор\")\n",
    "print(\"7. Цепь (+/-)\")\n",
    "print(\"8. Фаза\")\n",
    "print(\"9. Атрибуты\")\n",
    "\n",
    "# Показываем первые строки GFF\n",
    "!head GCF_000005845.2_ASM584v2_genomic.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c831643",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 6: ПАРСИНГ GFF ФАЙЛА\n",
    "\n",
    "Создаем функцию для извлечения информации о генах из GFF файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5190f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Парсинг GFF файла ===\")\n",
    "\n",
    "def parse_gff(filepath):\n",
    "    \"\"\"\n",
    "    Парсит GFF файл и извлекает информацию о генетических элементах\n",
    "    \n",
    "    Args:\n",
    "        filepath: путь к GFF файлу\n",
    "    \n",
    "    Returns:\n",
    "        list: список словарей с информацией о каждом элементе\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue  # Пропускаем комментарии и пустые строки\n",
    "\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) != 9:\n",
    "                continue  # Пропускаем некорректные строки\n",
    "\n",
    "            seqid, source, feature_type, start, end, score, strand, phase, attributes = parts\n",
    "\n",
    "            # Парсим колонку attributes в словарь\n",
    "            attr_dict = {}\n",
    "            for attr in attributes.split(';'):\n",
    "                if '=' in attr:\n",
    "                    key, value = attr.split('=', 1)\n",
    "                    attr_dict[key] = value\n",
    "\n",
    "            annotations.append({\n",
    "                'seqid': seqid,\n",
    "                'source': source,\n",
    "                'type': feature_type,\n",
    "                'start': int(start),\n",
    "                'end': int(end),\n",
    "                'score': score if score != '.' else None,\n",
    "                'strand': strand,\n",
    "                'phase': phase if phase != '.' else None,\n",
    "                'attributes': attr_dict\n",
    "            })\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Парсим GFF файл\n",
    "print(\"Парсинг GFF файла...\")\n",
    "annotations = parse_gff(\"GCF_000005845.2_ASM584v2_genomic.gff\")\n",
    "print(f\"Загружено {len(annotations)} аннотационных записей\")\n",
    "\n",
    "# Анализируем типы элементов\n",
    "from collections import Counter\n",
    "feature_types = Counter([ann['type'] for ann in annotations])\n",
    "print(\"\\nТипы генетических элементов:\")\n",
    "for feature_type, count in feature_types.most_common():\n",
    "    print(f\"  {feature_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4eaafa",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 7: АНАЛИЗ ДЛИН ГЕНОВ\n",
    "\n",
    "Строим распределение длин генов и находим экстремальные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Анализ длин генов ===\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gene_lengths(gff_file):\n",
    "    \"\"\"\n",
    "    Строит гистограмму распределения длин генов и находит экстремальные значения\n",
    "    \"\"\"\n",
    "    features = parse_gff(gff_file)\n",
    "    genes = [f for f in features if f['type'] == 'gene']\n",
    "    gene_lengths = [gene['end'] - gene['start'] + 1 for gene in genes]\n",
    "\n",
    "    if not gene_lengths:\n",
    "        print(\"Гены не найдены в GFF файле\")\n",
    "        return\n",
    "\n",
    "    # Находим самый короткий и самый длинный ген\n",
    "    min_length = min(gene_lengths)\n",
    "    max_length = max(gene_lengths)\n",
    "    avg_length = sum(gene_lengths) / len(gene_lengths)\n",
    "\n",
    "    min_index = gene_lengths.index(min_length)\n",
    "    max_index = gene_lengths.index(max_length)\n",
    "\n",
    "    # Строим гистограмму\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(gene_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.title(\"Распределение длин генов E.coli\")\n",
    "    plt.xlabel(\"Длина гена (нуклеотиды)\")\n",
    "    plt.ylabel(\"Количество генов\")\n",
    "    plt.axvline(avg_length, color='red', linestyle='--', label=f'Средняя длина: {avg_length:.0f} п.н.')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Выводим статистику\n",
    "    print(f\"Общее количество генов: {len(genes)}\")\n",
    "    print(f\"Самый короткий ген: {min_length} п.н.\")\n",
    "    print(f\"Самый длинный ген: {max_length} п.н.\")\n",
    "    print(f\"Средняя длина гена: {avg_length:.1f} п.н.\")\n",
    "    \n",
    "    # Информация о экстремальных генах\n",
    "    min_gene = genes[min_index]\n",
    "    max_gene = genes[max_index]\n",
    "    \n",
    "    print(f\"\\nСамый короткий ген:\")\n",
    "    print(f\"  ID: {min_gene['attributes'].get('ID', 'неизвестно')}\")\n",
    "    print(f\"  Позиция: {min_gene['start']}-{min_gene['end']}\")\n",
    "    \n",
    "    print(f\"\\nСамый длинный ген:\")\n",
    "    print(f\"  ID: {max_gene['attributes'].get('ID', 'неизвестно')}\")\n",
    "    print(f\"  Позиция: {max_gene['start']}-{max_gene['end']}\")\n",
    "\n",
    "# Анализируем длины генов E.coli\n",
    "gff_path = \"GCF_000005845.2_ASM584v2_genomic.gff\"\n",
    "plot_gene_lengths(gff_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ad64c",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 8: ПОИСК ОТКРЫТЫХ РАМОК СЧИТЫВАНИЯ (ORF)\n",
    "\n",
    "ОРФ (Open Reading Frame) - участок ДНК, который потенциально может кодировать белок.\n",
    "\n",
    "**Критерии ОРФ:**\n",
    "1. Начинается со стартового кодона (ATG)\n",
    "2. Заканчивается стоп-кодоном (TAA, TAG, TGA)\n",
    "3. Находится в одной рамке считывания (кратно 3 нуклеотидам)\n",
    "4. Не содержит промежуточных стоп-кодонов\n",
    "\n",
    "**У ДНК есть 6 возможных рамок считывания:**\n",
    "- 3 на прямой цепи (начиная с позиций 0, 1, 2)\n",
    "- 3 на обратной цепи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c902dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orfs_bacterial(dna_sequence: str) -> list:\n",
    "    \"\"\"\n",
    "    Находит открытые рамки считывания (ОРФ) в геномной последовательности.\n",
    "    \n",
    "    Алгоритм:\n",
    "    1. Ищем все ATG кодоны в каждой из 3 рамок считывания\n",
    "    2. Для каждого ATG ищем ближайший стоп-кодон в той же рамке\n",
    "    3. Проверяем, что ОРФ не вложен в уже найденный ОРФ той же рамки\n",
    "    \n",
    "    Args:\n",
    "        dna_sequence: последовательность ДНК\n",
    "    \n",
    "    Returns:\n",
    "        list: список словарей с информацией об ОРФах\n",
    "    \"\"\"\n",
    "    if not dna_sequence:\n",
    "        return []\n",
    "\n",
    "    dna_sequence = dna_sequence.upper()\n",
    "    n = len(dna_sequence)\n",
    "\n",
    "    start_codon = \"ATG\"\n",
    "    stop_codons = [\"TAA\", \"TAG\", \"TGA\"]\n",
    "\n",
    "    found_orfs = []\n",
    "    \n",
    "    # Для каждой рамки отслеживаем найденные ОРФы\n",
    "    identified_orf_regions_by_frame = {0: [], 1: [], 2: []}\n",
    "\n",
    "    # Анализируем 3 рамки считывания\n",
    "    for frame_offset in range(3):\n",
    "        print(f\"  Анализируем рамку {frame_offset + 1}...\")\n",
    "        \n",
    "        # Находим все ATG в текущей рамке\n",
    "        potential_atg_indices = []\n",
    "        for i in range(frame_offset, n - 2, 3):\n",
    "            codon = dna_sequence[i : i + 3]\n",
    "            if codon == start_codon:\n",
    "                potential_atg_indices.append(i)\n",
    "\n",
    "        print(f\"    Найдено {len(potential_atg_indices)} потенциальных стартовых кодонов\")\n",
    "\n",
    "        # Для каждого ATG ищем ОРФ\n",
    "        valid_orfs_in_frame = 0\n",
    "        for atg_start_index in potential_atg_indices:\n",
    "            # Проверяем, не вложен ли этот ATG в уже найденный ОРФ\n",
    "            is_nested = False\n",
    "            for orf_start, orf_end in identified_orf_regions_by_frame[frame_offset]:\n",
    "                if orf_start <= atg_start_index < orf_end:\n",
    "                    is_nested = True\n",
    "                    break\n",
    "\n",
    "            if is_nested:\n",
    "                continue\n",
    "\n",
    "            # Ищем первый стоп-кодон после ATG\n",
    "            for j in range(atg_start_index + 3, n - 2, 3):\n",
    "                codon = dna_sequence[j : j + 3]\n",
    "                if codon in stop_codons:\n",
    "                    orf_end_index = j + 3\n",
    "                    orf_sequence = dna_sequence[atg_start_index:orf_end_index]\n",
    "                    \n",
    "                    orf_info = {\n",
    "                        \"start\": atg_start_index,\n",
    "                        \"end\": orf_end_index,\n",
    "                        \"frame\": frame_offset + 1,\n",
    "                        \"sequence\": orf_sequence,\n",
    "                        \"length\": len(orf_sequence)\n",
    "                    }\n",
    "                    found_orfs.append(orf_info)\n",
    "                    \n",
    "                    # Запоминаем регион этого ОРФа\n",
    "                    identified_orf_regions_by_frame[frame_offset].append(\n",
    "                        (atg_start_index, orf_end_index)\n",
    "                    )\n",
    "                    valid_orfs_in_frame += 1\n",
    "                    break\n",
    "\n",
    "        print(f\"    Найдено {valid_orfs_in_frame} валидных ОРФов\")\n",
    "\n",
    "    # Сортируем по позиции\n",
    "    found_orfs.sort(key=lambda x: (x['start'], x['frame']))\n",
    "    return found_orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657214e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск ОРФов на обеих цепях\n",
    "print(\"Поиск ОРФов на прямой цепи:\")\n",
    "orfs_plus = find_orfs_bacterial(genome_sequence)\n",
    "\n",
    "print(\"\\nПоиск ОРФов на обратной цепи:\")\n",
    "orfs_minus = find_orfs_bacterial(reverse_complement(genome_sequence))\n",
    "\n",
    "print(f\"\\nРезультаты поиска ОРФов:\")\n",
    "print(f\"Прямая цепь:   {len(orfs_plus):,} ОРФов\")\n",
    "print(f\"Обратная цепь: {len(orfs_minus):,} ОРФов\")\n",
    "print(f\"Всего:         {len(orfs_plus) + len(orfs_minus):,} ОРФов\")\n",
    "\n",
    "# Показываем примеры найденных ОРФов\n",
    "print(\"\\nПримеры найденных ОРФов (первые 5):\")\n",
    "for i, orf in enumerate(orfs_plus[:5]):\n",
    "    print(f\"ОРФ {i+1}: позиция {orf['start']}-{orf['end']}, \"\n",
    "          f\"рамка {orf['frame']}, длина {orf['length']} п.н.\")\n",
    "    print(f\"  Последовательность: {orf['sequence'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68266a27",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 9: АНАЛИЗ РАСПРЕДЕЛЕНИЯ ДЛИН ОРФов\n",
    "\n",
    "Строим гистограммы распределения длин найденных ОРФов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Анализ распределения длин ОРФов ===\")\n",
    "\n",
    "def plot_orf_length_distribution(orfs_list, title=\"Распределение длин ОРФов\"):\n",
    "    \"\"\"\n",
    "    Строит гистограмму распределения длин ОРФов\n",
    "    \"\"\"\n",
    "    if not orfs_list:\n",
    "        print(f\"ОРФы не найдены для: {title}\")\n",
    "        return\n",
    "\n",
    "    orf_lengths = [orf['length'] for orf in orfs_list]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(orf_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Длина ОРФа (нуклеотиды)\")\n",
    "    plt.ylabel(\"Количество ОРФов\")\n",
    "    plt.yscale('log')  # Логарифмическая шкала для лучшей визуализации\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Статистика\n",
    "    min_length = min(orf_lengths)\n",
    "    max_length = max(orf_lengths)\n",
    "    avg_length = sum(orf_lengths) / len(orf_lengths)\n",
    "    \n",
    "    print(f\"Общее количество ОРФов: {len(orf_lengths):,}\")\n",
    "    print(f\"Самый короткий ОРФ: {min_length} п.н.\")\n",
    "    print(f\"Самый длинный ОРФ: {max_length} п.н.\")\n",
    "    print(f\"Средняя длина ОРФа: {avg_length:.1f} п.н.\")\n",
    "\n",
    "# Анализируем распределение длин\n",
    "plot_orf_length_distribution(orfs_plus, \"Распределение длин ОРФов (прямая цепь)\")\n",
    "plot_orf_length_distribution(orfs_minus, \"Распределение длин ОРФов (обратная цепь)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0635bf3",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 10: ИЗВЛЕЧЕНИЕ РЕФЕРЕНСНЫХ ГЕНОВ ИЗ GFF\n",
    "\n",
    "Извлекаем последовательности реальных генов для сравнения с нашими предсказаниями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d581d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Извлечение референсных генов из GFF ===\")\n",
    "\n",
    "# Загружаем BioPython если его нет\n",
    "try:\n",
    "    from Bio import SeqIO\n",
    "except ImportError:\n",
    "    print(\"Устанавливаем BioPython...\")\n",
    "    !pip install biopython\n",
    "    from Bio import SeqIO\n",
    "\n",
    "import csv\n",
    "\n",
    "def extract_orfs_from_gff(gff_file, fasta_file):\n",
    "    \"\"\"\n",
    "    Извлекает последовательности генов из GFF аннотации и FASTA файла\n",
    "    \"\"\"\n",
    "    # Загружаем последовательности\n",
    "    seq_dict = SeqIO.to_dict(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "    orfs = []\n",
    "\n",
    "    with open(gff_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 9 or row[0].startswith('#') or row[2] != 'gene':\n",
    "                continue\n",
    "                \n",
    "            chrom = row[0]\n",
    "            start = int(row[3]) - 1  # Конвертируем в 0-based координаты\n",
    "            end = int(row[4])\n",
    "            strand = row[6]\n",
    "\n",
    "            # Извлекаем последовательность\n",
    "            sequence = seq_dict[chrom].seq[start:end]\n",
    "            if strand == '-':\n",
    "                continue  # Пока анализируем только прямую цепь\n",
    "                \n",
    "            orfs.append({\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'frame': (start) % 3,  # Упрощенное определение рамки\n",
    "                'sequence': str(sequence),\n",
    "                'length': end - start\n",
    "            })\n",
    "\n",
    "    return orfs\n",
    "\n",
    "# Извлекаем референсные гены\n",
    "print(\"Извлечение референсных генов из аннотации...\")\n",
    "gff_file = \"GCF_000005845.2_ASM584v2_genomic.gff\"\n",
    "fasta_file = \"GCF_000005845.2_ASM584v2_genomic.fna\"\n",
    "reference_orfs = extract_orfs_from_gff(gff_file, fasta_file)\n",
    "\n",
    "print(f\"Извлечено {len(reference_orfs)} референсных генов\")\n",
    "print(f\"Предсказано {len(orfs_plus)} ОРФов\")\n",
    "\n",
    "# Показываем пример референсного гена\n",
    "if reference_orfs:\n",
    "    print(f\"\\nПример референсного гена:\")\n",
    "    ref_gene = reference_orfs[0]\n",
    "    print(f\"Позиция: {ref_gene['start']}-{ref_gene['end']}\")\n",
    "    print(f\"Длина: {ref_gene['length']} п.н.\")\n",
    "    print(f\"Последовательность: {ref_gene['sequence'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec037093",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 11: ОЦЕНКА КАЧЕСТВА ПРЕДСКАЗАНИЯ\n",
    "\n",
    "Для оценки качества предсказания используем стандартные метрики:\n",
    "\n",
    "- **True Positive (TP)** - правильно предсказанные гены\n",
    "- **False Positive (FP)** - ложно предсказанные гены (предсказали, но гена нет)\n",
    "- **False Negative (FN)** - пропущенные гены (ген есть, но не предсказали)\n",
    "\n",
    "**Метрики:**\n",
    "- **Precision (точность)** = TP / (TP + FP) - доля правильных среди предсказанных\n",
    "- **Recall (полнота)** = TP / (TP + FN) - доля найденных среди всех реальных\n",
    "- **F1-score** = 2 * (Precision * Recall) / (Precision + Recall) - гармоническое среднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def match_orfs(predicted, truth, tolerance=0):\n",
    "    \"\"\"\n",
    "    Сопоставляет предсказанные ОРФы с референсными\n",
    "    \n",
    "    Args:\n",
    "        predicted: список предсказанных ОРФов\n",
    "        truth: список референсных ОРФов\n",
    "        tolerance: допустимое отклонение в координатах\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (TP, FP, FN)\n",
    "    \"\"\"\n",
    "    pred_intervals = [(orf['start'], orf['end']) for orf in predicted]\n",
    "    true_intervals = [(orf['start'], orf['end']) for orf in truth]\n",
    "    \n",
    "    matched_true = set()\n",
    "    tp = 0  # True Positives\n",
    "    fp = 0  # False Positives\n",
    "\n",
    "    # Проверяем каждый предсказанный ОРФ\n",
    "    for p_start, p_end in pred_intervals:\n",
    "        found_match = False\n",
    "        for idx, (t_start, t_end) in enumerate(true_intervals):\n",
    "            if idx in matched_true:\n",
    "                continue\n",
    "            \n",
    "            # Проверяем совпадение координат с допуском\n",
    "            if (abs(p_start - t_start) <= tolerance and \n",
    "                abs(p_end - t_end) <= tolerance):\n",
    "                tp += 1\n",
    "                matched_true.add(idx)\n",
    "                found_match = True\n",
    "                break\n",
    "        \n",
    "        if not found_match:\n",
    "            fp += 1\n",
    "\n",
    "    fn = len(true_intervals) - len(matched_true)  # False Negatives\n",
    "    return tp, fp, fn\n",
    "\n",
    "def compute_metrics(tp, fp, fn):\n",
    "    \"\"\"Вычисляет метрики качества\"\"\"\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    accuracy = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'TP': tp,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(precision, 4),\n",
    "        'Recall': round(recall, 4),\n",
    "        'F1 Score': round(f1, 4),\n",
    "    }\n",
    "\n",
    "def evaluate_prediction(predicted_orfs, reference_orfs, tolerance=0):\n",
    "    \"\"\"Оценивает качество предсказания и выводит результаты\"\"\"\n",
    "    tp, fp, fn = match_orfs(predicted_orfs, reference_orfs, tolerance)\n",
    "    metrics = compute_metrics(tp, fp, fn)\n",
    "    \n",
    "    print(f\"Результаты оценки (допуск ±{tolerance} п.н.):\")\n",
    "    print(\"-\" * 50)\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric:12}: {value}\")\n",
    "    \n",
    "    print(f\"\\nИнтерпретация:\")\n",
    "    print(f\"- Из {len(reference_orfs)} реальных генов найдено {tp} ({metrics['Recall']*100:.1f}%)\")\n",
    "    print(f\"- Из {len(predicted_orfs)} предсказанных {tp} правильные ({metrics['Precision']*100:.1f}%)\")\n",
    "    print(f\"- Пропущено {fn} генов\")\n",
    "    print(f\"- Ложно предсказано {fp} генов\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Оценка базового предсказания\n",
    "print(\"Оценка базового алгоритма поиска ОРФов:\")\n",
    "metrics_base = evaluate_prediction(orfs_plus, reference_orfs, tolerance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53656536",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 12: ФИЛЬТРАЦИЯ ОРФов ПО ДЛИНЕ\n",
    "\n",
    "Большинство найденных ОРФов очень короткие и вряд ли кодируют белки. Применим фильтр по минимальной длине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22614d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Фильтрация ОРФов по длине ===\")\n",
    "print(\"Большинство найденных ОРФов очень короткие и вряд ли кодируют белки\")\n",
    "print(\"Применим фильтр: оставим только ОРФы длиннее 150 нуклеотидов (50 аминокислот)\")\n",
    "\n",
    "# Фильтруем короткие ОРФы\n",
    "min_length = 150  # нуклеотидов\n",
    "orfs_filtered = [orf for orf in orfs_plus if orf[\"length\"] >= min_length]\n",
    "\n",
    "print(f\"До фильтрации: {len(orfs_plus):,} ОРФов\")\n",
    "print(f\"После фильтрации: {len(orfs_filtered):,} ОРФов\")\n",
    "print(f\"Отфильтровано: {len(orfs_plus) - len(orfs_filtered):,} коротких ОРФов\")\n",
    "\n",
    "# Оценка после фильтрации\n",
    "print(\"\\nОценка после фильтрации по длине:\")\n",
    "metrics_filtered = evaluate_prediction(orfs_filtered, reference_orfs, tolerance=0)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(f\"\\nСравнение результатов:\")\n",
    "print(f\"{'Метрика':<12} {'Базовый':<10} {'Фильтрация':<12} {'Изменение'}\")\n",
    "print(\"-\" * 50)\n",
    "for metric in ['Precision', 'Recall', 'F1 Score']:\n",
    "    base_val = metrics_base[metric]\n",
    "    filt_val = metrics_filtered[metric]\n",
    "    change = filt_val - base_val\n",
    "    change_str = f\"{change:+.3f}\"\n",
    "    print(f\"{metric:<12} {base_val:<10.3f} {filt_val:<12.3f} {change_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206af8d9",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 13: АНАЛИЗ ОШИБОК ПРЕДСКАЗАНИЯ\n",
    "\n",
    "Подробный анализ того, где наш алгоритм ошибается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Анализ ошибок предсказания ===\")\n",
    "\n",
    "def analyze_prediction_errors(predicted, reference, tolerance=0):\n",
    "    \"\"\"\n",
    "    Подробный анализ того, где наш алгоритм ошибается\n",
    "    \"\"\"\n",
    "    # Классифицируем каждый предсказанный ОРФ\n",
    "    matched_ref = set()\n",
    "    classified_pred = []\n",
    "    \n",
    "    for pred_orf in predicted:\n",
    "        match_type = 'FP'  # По умолчанию False Positive\n",
    "        \n",
    "        for idx, ref_orf in enumerate(reference):\n",
    "            if idx in matched_ref:\n",
    "                continue\n",
    "                \n",
    "            # Проверяем разные типы совпадений\n",
    "            start_match = abs(pred_orf['start'] - ref_orf['start']) <= tolerance\n",
    "            end_match = abs(pred_orf['end'] - ref_orf['end']) <= tolerance\n",
    "            \n",
    "            if start_match and end_match:\n",
    "                match_type = 'TP-full'  # Полное совпадение\n",
    "                matched_ref.add(idx)\n",
    "                break\n",
    "            elif start_match:\n",
    "                match_type = 'TP-start'  # Совпадает только начало\n",
    "                matched_ref.add(idx)\n",
    "                break\n",
    "            elif end_match:\n",
    "                match_type = 'TP-end'  # Совпадает только конец\n",
    "                matched_ref.add(idx)\n",
    "                break\n",
    "        \n",
    "        classified_pred.append({**pred_orf, 'type': match_type})\n",
    "    \n",
    "    # Классифицируем референсные ОРФы\n",
    "    classified_ref = []\n",
    "    for idx, ref_orf in enumerate(reference):\n",
    "        ref_type = 'FN' if idx not in matched_ref else 'TP'\n",
    "        classified_ref.append({**ref_orf, 'type': ref_type})\n",
    "    \n",
    "    return classified_pred, classified_ref\n",
    "\n",
    "# Анализируем ошибки\n",
    "print(\"Классификация предсказанных ОРФов...\")\n",
    "pred_classified, ref_classified = analyze_prediction_errors(\n",
    "    orfs_filtered, reference_orfs, tolerance=0\n",
    ")\n",
    "\n",
    "# Подсчитываем типы совпадений\n",
    "from collections import Counter\n",
    "pred_types = Counter([orf['type'] for orf in pred_classified])\n",
    "\n",
    "print(\"Результаты классификации:\")\n",
    "print(f\"  Полные совпадения (TP-full):  {pred_types['TP-full']}\")\n",
    "print(f\"  Совпадения по началу:         {pred_types['TP-start']}\")\n",
    "print(f\"  Совпадения по концу:          {pred_types['TP-end']}\")\n",
    "print(f\"  Ложные предсказания (FP):     {pred_types['FP']}\")\n",
    "\n",
    "fn_count = len([orf for orf in ref_classified if orf['type'] == 'FN'])\n",
    "print(f\"  Пропущенные гены (FN):        {fn_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906495d4",
   "metadata": {},
   "source": [
    "## ЧАСТЬ 14: АНАЛИЗ GC-СОСТАВА\n",
    "\n",
    "GC-состав может помочь отличить настоящие гены от случайных ОРФов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Анализ GC-состава ===\")\n",
    "print(\"GC-состав может помочь отличить настоящие гены от случайных ОРФов\")\n",
    "\n",
    "def gc_content(sequence):\n",
    "    \"\"\"Вычисляет GC-состав последовательности (в процентах)\"\"\"\n",
    "    sequence = sequence.upper()\n",
    "    gc_count = sequence.count('G') + sequence.count('C')\n",
    "    return 100 * gc_count / len(sequence) if len(sequence) > 0 else 0\n",
    "\n",
    "def compare_gc_content(predicted_classified):\n",
    "    \"\"\"Сравнивает GC-состав правильных и ложных предсказаний\"\"\"\n",
    "    tp_gc = []\n",
    "    fp_gc = []\n",
    "    \n",
    "    for orf in predicted_classified:\n",
    "        gc = gc_content(orf['sequence'])\n",
    "        if orf['type'] == 'TP-full':\n",
    "            tp_gc.append(gc)\n",
    "        elif orf['type'] == 'FP':\n",
    "            fp_gc.append(gc)\n",
    "    \n",
    "    if tp_gc and fp_gc:\n",
    "        avg_tp = sum(tp_gc) / len(tp_gc)\n",
    "        avg_fp = sum(fp_gc) / len(fp_gc)\n",
    "        \n",
    "        print(f\"Средний GC-состав:\")\n",
    "        print(f\"  Правильные предсказания: {avg_tp:.1f}% (n={len(tp_gc)})\")\n",
    "        print(f\"  Ложные предсказания:     {avg_fp:.1f}% (n={len(fp_gc)})\")\n",
    "        \n",
    "        # Строим гистограмму\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(tp_gc, bins=20, alpha=0.7, label='Правильные (TP)', density=True)\n",
    "        plt.hist(fp_gc, bins=20, alpha=0.7, label='Ложные (FP)', density=True)\n",
    "        plt.xlabel('GC-состав (%)')\n",
    "        plt.ylabel('Плотность')\n",
    "        plt.title('Распределение GC-состава: правильные vs ложные предсказания')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return avg_tp, avg_fp\n",
    "    else:\n",
    "        print(\"Недостаточно данных для анализа GC-состава\")\n",
    "        return None, None\n",
    "\n",
    "# Анализируем GC-состав\n",
    "tp_gc, fp_gc = compare_gc_content(pred_classified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17176a82",
   "metadata": {},
   "source": [
    "## ЗАКЛЮЧЕНИЕ\n",
    "\n",
    "Результаты анализа показывают важность комплексного подхода к предсказанию генов и необходимость использования множественных критериев для отличия настоящих генов от случайных открытых рамок считывания.\n",
    "\n",
    "### Основные выводы:\n",
    "1. **Высокий уровень ложных предсказаний** - большинство ОРФов не являются генами\n",
    "2. **Простой поиск по стартовым/стоп-кодонам недостаточен**\n",
    "3. **Нужны дополнительные фильтры** (GC-состав, Shine-Dalgarno, кодонное смещение)\n",
    "\n",
    "### Возможные улучшения:\n",
    "1. Поиск Shine-Dalgarno последовательностей перед ATG\n",
    "2. Анализ кодонного смещения\n",
    "3. Машинное обучение на признаках последовательностей\n",
    "4. Сравнительная геномика\n",
    "5. Анализ экспрессии (RNA-seq данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ЗАКЛЮЧЕНИЕ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Результаты анализа генома E.coli:\n",
    "\n",
    "📊 СТАТИСТИКА ГЕНОМА:\n",
    "  • Длина генома: {len(genome_sequence):,} нуклеотидов\n",
    "  • Референсных генов: {len(reference_orfs)}\n",
    "  • Найдено потенциальных ОРФов: {len(orfs_plus):,}\n",
    "  • После фильтрации по длине: {len(orfs_filtered):,}\n",
    "\n",
    "🎯 КАЧЕСТВО ПРЕДСКАЗАНИЯ:\n",
    "  • Точность (Precision): {metrics_filtered['Precision']:.1%}\n",
    "  • Полнота (Recall): {metrics_filtered['Recall']:.1%}\n",
    "  • F1-мера: {metrics_filtered['F1 Score']:.3f}\n",
    "\n",
    "🔍 ОСНОВНЫЕ ПРОБЛЕМЫ:\n",
    "  1. Высокий уровень ложных предсказаний - большинство ОРФов не являются генами\n",
    "  2. Простой поиск по стартовым/стоп-кодонам недостаточен\n",
    "  3. Нужны дополнительные фильтры (GC-состав, Shine-Dalgarno, кодонное смещение)\n",
    "\n",
    "💡 ВОЗМОЖНЫЕ УЛУЧШЕНИЯ:\n",
    "  1. Поиск Shine-Dalgarno последовательностей перед ATG\n",
    "  2. Анализ кодонного смещения\n",
    "  3. Машинное обучение на признаках последовательностей\n",
    "  4. Сравнительная геномика\n",
    "  5. Анализ экспрессии (RNA-seq данные)\n",
    "\n",
    "Этот анализ показывает важность комплексного подхода к предсказанию генов\n",
    "и необходимость использования множественных критериев для отличия \n",
    "настоящих генов от случайных открытых рамок считывания.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nНастройте параметры фильтрации и попробуйте другие подходы!\")\n",
    "print(\"Удачи в изучении биоинформатики! 🧬\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
