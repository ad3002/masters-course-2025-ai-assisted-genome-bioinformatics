{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1a9bb7",
   "metadata": {},
   "source": [
    "# Bioinformatics Genome Analysis: Gene Finding and Prediction\n",
    "\n",
    "This notebook demonstrates fundamental methods for working with genomic data:\n",
    "1. Loading and parsing genomic files (FASTA, GFF)\n",
    "2. Finding open reading frames (ORF)\n",
    "3. Comparing predicted genes with reference data\n",
    "4. Evaluating prediction quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e5d72",
   "metadata": {},
   "source": [
    "## PART 1: LOADING E.COLI DATA\n",
    "\n",
    "Loading the reference genome of Escherichia coli strain K-12 - one of the most well-studied bacterial genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Loading E.coli genome ===\")\n",
    "print(\"Downloading reference genome of Escherichia coli strain K-12\")\n",
    "print(\"This is one of the most well-studied bacterial genomes\")\n",
    "\n",
    "# Download compressed E.coli genome\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.fna.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check downloaded file size\n",
    "!ls -hlrt\n",
    "\n",
    "print(\"\\nDecompressing genome...\")\n",
    "# Decompress archive\n",
    "!gzip -d GCF_000005845.2_ASM584v2_genomic.fna.gz\n",
    "\n",
    "# Check decompressed file size\n",
    "!ls -hlrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nViewing file header:\")\n",
    "print(\"FASTA format contains:\")\n",
    "print(\"- Header starting with '>'\")\n",
    "print(\"- DNA sequence in standard symbols (A, T, G, C)\")\n",
    "\n",
    "# View first 10 lines of genome\n",
    "!head GCF_000005845.2_ASM584v2_genomic.fna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e12a81",
   "metadata": {},
   "source": [
    "## PART 2: PARSING FASTA FILE\n",
    "\n",
    "Creating a function to read FASTA format and load genomic sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Parsing FASTA file ===\")\n",
    "print(\"Creating function to read FASTA format\")\n",
    "\n",
    "def parse_fasta(filepath):\n",
    "    \"\"\"\n",
    "    Parses FASTA file and returns pairs (header, sequence)\n",
    "    \n",
    "    FASTA format:\n",
    "    >Sequence_header\n",
    "    ATGCGATCGATCG...\n",
    "    ATCGATCGATCGA...\n",
    "    \n",
    "    Args:\n",
    "        filepath: path to FASTA file\n",
    "    \n",
    "    Yields:\n",
    "        tuple: (header, sequence)\n",
    "    \"\"\"\n",
    "    header = None\n",
    "    sequence_lines = []\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove spaces and newline characters\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            if line.startswith('>'):\n",
    "                if header is not None:\n",
    "                    # If header exists, return previous sequence\n",
    "                    yield header, ''.join(sequence_lines)\n",
    "                header = line[1:]  # Remove '>' at beginning\n",
    "                sequence_lines = []  # Reset buffer for new sequence\n",
    "            else:\n",
    "                sequence_lines.append(line)\n",
    "\n",
    "        # Return last sequence in file\n",
    "        if header is not None:\n",
    "            yield header, ''.join(sequence_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610bff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply parser to our file\n",
    "fasta_path = \"GCF_000005845.2_ASM584v2_genomic.fna\"\n",
    "\n",
    "print(\"Analyzing FASTA file structure:\")\n",
    "for header, sequence in parse_fasta(fasta_path):\n",
    "    print(\"Header:\", header)\n",
    "    print(\"Sequence length:\", len(sequence), \"nucleotides\")\n",
    "    print(\"First 60 characters:\", sequence[:60] + '...')\n",
    "    \n",
    "    # Save sequence for further analysis\n",
    "    genome_sequence = sequence\n",
    "    break  # E.coli has one chromosome, so take the first\n",
    "\n",
    "print(f\"\\nComplete E.coli genome length: {len(genome_sequence):,} nucleotides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b9dea",
   "metadata": {},
   "source": [
    "## PART 3: BASIC DNA OPERATIONS\n",
    "\n",
    "DNA is double-stranded, and genes can be located on either strand. To analyze the opposite strand, we need to compute the reverse complement sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b558cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Basic DNA operations ===\")\n",
    "\n",
    "def reverse_complement(dna_seq):\n",
    "    \"\"\"\n",
    "    Computes reverse complement DNA sequence\n",
    "    \n",
    "    DNA is double-stranded, and genes can be on either strand.\n",
    "    To analyze the opposite strand we need to:\n",
    "    1. Replace each nucleotide with its complement (A‚ÜîT, G‚ÜîC)\n",
    "    2. Reverse the sequence (read right to left)\n",
    "    \n",
    "    Args:\n",
    "        dna_seq: DNA sequence\n",
    "    \n",
    "    Returns:\n",
    "        str: reverse complement sequence\n",
    "    \"\"\"\n",
    "    complement = {\n",
    "        'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G',\n",
    "        'a': 't', 't': 'a', 'g': 'c', 'c': 'g',\n",
    "        'N': 'N', 'n': 'n'  # N denotes undefined nucleotide\n",
    "    }\n",
    "    reversed_seq = dna_seq[::-1]  # Reverse sequence\n",
    "    rev_comp = ''.join(complement.get(base, base) for base in reversed_seq)\n",
    "    return rev_comp\n",
    "\n",
    "# Demonstrate function\n",
    "test_seq = \"ATGCGATCG\"\n",
    "print(f\"Original sequence:      {test_seq}\")\n",
    "print(f\"Reverse complement:     {reverse_complement(test_seq)}\")\n",
    "\n",
    "print(f\"\\nGenome length: {len(genome_sequence):,} bp\")\n",
    "\n",
    "# Create reverse complement sequence for minus strand analysis\n",
    "rev_comp_sequence = reverse_complement(genome_sequence)\n",
    "print(\"Reverse complement sequence created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71620a62",
   "metadata": {},
   "source": [
    "## PART 4: FINDING START CODONS\n",
    "\n",
    "In bacteria, genes usually start with the start codon ATG (methionine). Let's analyze their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ca7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Start codon analysis ===\")\n",
    "print(\"In bacteria, genes usually start with start codon ATG (methionine)\")\n",
    "\n",
    "# Count start codons on both strands\n",
    "methionine_start = \"ATG\"\n",
    "methionine_start_rc = \"CAT\"  # ATG on reverse strand appears as CAT on forward\n",
    "\n",
    "hits_plus = genome_sequence.count(methionine_start)\n",
    "hits_minus = genome_sequence.count(methionine_start_rc)\n",
    "\n",
    "print(f\"Start codons ATG on plus strand:  {hits_plus:,}\")\n",
    "print(f\"Start codons ATG on minus strand: {hits_minus:,}\")\n",
    "print(f\"Total ATG count:                  {hits_plus + hits_minus:,}\")\n",
    "\n",
    "print(f\"\\nATG frequency: {(hits_plus + hits_minus) / len(genome_sequence) * 1000:.2f} per 1000 bp\")\n",
    "print(\"This roughly corresponds to random distribution (expected ATG frequency = 1/64 ‚âà 0.016)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9403f",
   "metadata": {},
   "source": [
    "## PART 5: LOADING GENE ANNOTATION (GFF)\n",
    "\n",
    "GFF (General Feature Format) contains gene coordinates and descriptions - reference data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41faeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Loading gene annotation ===\")\n",
    "print(\"GFF (General Feature Format) contains gene coordinates and descriptions\")\n",
    "\n",
    "# Download GFF file with E.coli annotation\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gff.gz\n",
    "\n",
    "# Decompress\n",
    "!gzip -d GCF_000005845.2_ASM584v2_genomic.gff.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nViewing GFF file structure:\")\n",
    "print(\"GFF contains 9 columns:\")\n",
    "print(\"1. Chromosome/contig\")\n",
    "print(\"2. Annotation source\") \n",
    "print(\"3. Feature type (gene, CDS, etc.)\")\n",
    "print(\"4. Start (1-based)\")\n",
    "print(\"5. End (inclusive)\")\n",
    "print(\"6. Score\")\n",
    "print(\"7. Strand (+/-)\")\n",
    "print(\"8. Phase\")\n",
    "print(\"9. Attributes\")\n",
    "\n",
    "# Show first lines of GFF\n",
    "!head GCF_000005845.2_ASM584v2_genomic.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5b6cb",
   "metadata": {},
   "source": [
    "## PART 6: PARSING GFF FILE\n",
    "\n",
    "Creating a function to extract gene information from GFF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Parsing GFF file ===\")\n",
    "\n",
    "def parse_gff(filepath):\n",
    "    \"\"\"\n",
    "    Parses GFF file and extracts genetic element information\n",
    "    \n",
    "    Args:\n",
    "        filepath: path to GFF file\n",
    "    \n",
    "    Returns:\n",
    "        list: list of dictionaries with information about each element\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue  # Skip comments and empty lines\n",
    "\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) != 9:\n",
    "                continue  # Skip incorrect lines\n",
    "\n",
    "            seqid, source, feature_type, start, end, score, strand, phase, attributes = parts\n",
    "\n",
    "            # Parse attributes column into dictionary\n",
    "            attr_dict = {}\n",
    "            for attr in attributes.split(';'):\n",
    "                if '=' in attr:\n",
    "                    key, value = attr.split('=', 1)\n",
    "                    attr_dict[key] = value\n",
    "\n",
    "            annotations.append({\n",
    "                'seqid': seqid,\n",
    "                'source': source,\n",
    "                'type': feature_type,\n",
    "                'start': int(start),\n",
    "                'end': int(end),\n",
    "                'score': score if score != '.' else None,\n",
    "                'strand': strand,\n",
    "                'phase': phase if phase != '.' else None,\n",
    "                'attributes': attr_dict\n",
    "            })\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Parse GFF file\n",
    "print(\"Parsing GFF file...\")\n",
    "annotations = parse_gff(\"GCF_000005845.2_ASM584v2_genomic.gff\")\n",
    "print(f\"Loaded {len(annotations)} annotation records\")\n",
    "\n",
    "# Analyze element types\n",
    "from collections import Counter\n",
    "feature_types = Counter([ann['type'] for ann in annotations])\n",
    "print(\"\\nGenetic element types:\")\n",
    "for feature_type, count in feature_types.most_common():\n",
    "    print(f\"  {feature_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98254bf",
   "metadata": {},
   "source": [
    "## PART 7: GENE LENGTH ANALYSIS\n",
    "\n",
    "Building gene length distribution and finding extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Gene length analysis ===\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gene_lengths(gff_file):\n",
    "    \"\"\"\n",
    "    Plots histogram of gene length distribution and finds extreme values\n",
    "    \"\"\"\n",
    "    features = parse_gff(gff_file)\n",
    "    genes = [f for f in features if f['type'] == 'gene']\n",
    "    gene_lengths = [gene['end'] - gene['start'] + 1 for gene in genes]\n",
    "\n",
    "    if not gene_lengths:\n",
    "        print(\"No genes found in GFF file\")\n",
    "        return\n",
    "\n",
    "    # Find shortest and longest genes\n",
    "    min_length = min(gene_lengths)\n",
    "    max_length = max(gene_lengths)\n",
    "    avg_length = sum(gene_lengths) / len(gene_lengths)\n",
    "\n",
    "    min_index = gene_lengths.index(min_length)\n",
    "    max_index = gene_lengths.index(max_length)\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(gene_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.title(\"E.coli Gene Length Distribution\")\n",
    "    plt.xlabel(\"Gene length (nucleotides)\")\n",
    "    plt.ylabel(\"Number of genes\")\n",
    "    plt.axvline(avg_length, color='red', linestyle='--', label=f'Average length: {avg_length:.0f} bp')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Total number of genes: {len(genes)}\")\n",
    "    print(f\"Shortest gene: {min_length} bp\")\n",
    "    print(f\"Longest gene: {max_length} bp\")\n",
    "    print(f\"Average gene length: {avg_length:.1f} bp\")\n",
    "    \n",
    "    # Information about extreme genes\n",
    "    min_gene = genes[min_index]\n",
    "    max_gene = genes[max_index]\n",
    "    \n",
    "    print(f\"\\nShortest gene:\")\n",
    "    print(f\"  ID: {min_gene['attributes'].get('ID', 'unknown')}\")\n",
    "    print(f\"  Position: {min_gene['start']}-{min_gene['end']}\")\n",
    "    \n",
    "    print(f\"\\nLongest gene:\")\n",
    "    print(f\"  ID: {max_gene['attributes'].get('ID', 'unknown')}\")\n",
    "    print(f\"  Position: {max_gene['start']}-{max_gene['end']}\")\n",
    "\n",
    "# Analyze E.coli gene lengths\n",
    "gff_path = \"GCF_000005845.2_ASM584v2_genomic.gff\"\n",
    "plot_gene_lengths(gff_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7637cf7",
   "metadata": {},
   "source": [
    "## PART 8: FINDING OPEN READING FRAMES (ORF)\n",
    "\n",
    "ORF (Open Reading Frame) - a DNA region that potentially codes for a protein.\n",
    "\n",
    "**ORF criteria:**\n",
    "1. Starts with start codon (ATG)\n",
    "2. Ends with stop codon (TAA, TAG, TGA)\n",
    "3. Is in one reading frame (multiple of 3 nucleotides)\n",
    "4. Contains no intermediate stop codons\n",
    "\n",
    "**DNA has 6 possible reading frames:**\n",
    "- 3 on forward strand (starting at positions 0, 1, 2)\n",
    "- 3 on reverse strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ba236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_orfs_bacterial(dna_sequence: str) -> list:\n",
    "    \"\"\"\n",
    "    Finds open reading frames (ORFs) in genomic sequence.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Find all ATG codons in each of 3 reading frames\n",
    "    2. For each ATG find nearest stop codon in same frame\n",
    "    3. Check that ORF is not nested in already found ORF of same frame\n",
    "    \n",
    "    Args:\n",
    "        dna_sequence: DNA sequence\n",
    "    \n",
    "    Returns:\n",
    "        list: list of dictionaries with ORF information\n",
    "    \"\"\"\n",
    "    if not dna_sequence:\n",
    "        return []\n",
    "\n",
    "    dna_sequence = dna_sequence.upper()\n",
    "    n = len(dna_sequence)\n",
    "\n",
    "    start_codon = \"ATG\"\n",
    "    stop_codons = [\"TAA\", \"TAG\", \"TGA\"]\n",
    "\n",
    "    found_orfs = []\n",
    "    \n",
    "    # Track found ORFs for each frame\n",
    "    identified_orf_regions_by_frame = {0: [], 1: [], 2: []}\n",
    "\n",
    "    # Analyze 3 reading frames\n",
    "    for frame_offset in range(3):\n",
    "        print(f\"  Analyzing frame {frame_offset + 1}...\")\n",
    "        \n",
    "        # Find all ATG in current frame\n",
    "        potential_atg_indices = []\n",
    "        for i in range(frame_offset, n - 2, 3):\n",
    "            codon = dna_sequence[i : i + 3]\n",
    "            if codon == start_codon:\n",
    "                potential_atg_indices.append(i)\n",
    "\n",
    "        print(f\"    Found {len(potential_atg_indices)} potential start codons\")\n",
    "\n",
    "        # For each ATG find ORF\n",
    "        valid_orfs_in_frame = 0\n",
    "        for atg_start_index in potential_atg_indices:\n",
    "            # Check if this ATG is nested in already found ORF\n",
    "            is_nested = False\n",
    "            for orf_start, orf_end in identified_orf_regions_by_frame[frame_offset]:\n",
    "                if orf_start <= atg_start_index < orf_end:\n",
    "                    is_nested = True\n",
    "                    break\n",
    "\n",
    "            if is_nested:\n",
    "                continue\n",
    "\n",
    "            # Find first stop codon after ATG\n",
    "            for j in range(atg_start_index + 3, n - 2, 3):\n",
    "                codon = dna_sequence[j : j + 3]\n",
    "                if codon in stop_codons:\n",
    "                    orf_end_index = j + 3\n",
    "                    orf_sequence = dna_sequence[atg_start_index:orf_end_index]\n",
    "                    \n",
    "                    orf_info = {\n",
    "                        \"start\": atg_start_index,\n",
    "                        \"end\": orf_end_index,\n",
    "                        \"frame\": frame_offset + 1,\n",
    "                        \"sequence\": orf_sequence,\n",
    "                        \"length\": len(orf_sequence)\n",
    "                    }\n",
    "                    found_orfs.append(orf_info)\n",
    "                    \n",
    "                    # Remember this ORF region\n",
    "                    identified_orf_regions_by_frame[frame_offset].append(\n",
    "                        (atg_start_index, orf_end_index)\n",
    "                    )\n",
    "                    valid_orfs_in_frame += 1\n",
    "                    break\n",
    "\n",
    "        print(f\"    Found {valid_orfs_in_frame} valid ORFs\")\n",
    "\n",
    "    # Sort by position\n",
    "    found_orfs.sort(key=lambda x: (x['start'], x['frame']))\n",
    "    return found_orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf9977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ORFs on both strands\n",
    "print(\"Finding ORFs on forward strand:\")\n",
    "orfs_plus = find_orfs_bacterial(genome_sequence)\n",
    "\n",
    "print(\"\\nFinding ORFs on reverse strand:\")\n",
    "orfs_minus = find_orfs_bacterial(reverse_complement(genome_sequence))\n",
    "\n",
    "print(f\"\\nORF search results:\")\n",
    "print(f\"Forward strand:  {len(orfs_plus):,} ORFs\")\n",
    "print(f\"Reverse strand:  {len(orfs_minus):,} ORFs\")\n",
    "print(f\"Total:           {len(orfs_plus) + len(orfs_minus):,} ORFs\")\n",
    "\n",
    "# Show examples of found ORFs\n",
    "print(\"\\nExamples of found ORFs (first 5):\")\n",
    "for i, orf in enumerate(orfs_plus[:5]):\n",
    "    print(f\"ORF {i+1}: position {orf['start']}-{orf['end']}, \"\n",
    "          f\"frame {orf['frame']}, length {orf['length']} bp\")\n",
    "    print(f\"  Sequence: {orf['sequence'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e710037",
   "metadata": {},
   "source": [
    "## PART 9: ORF LENGTH DISTRIBUTION ANALYSIS\n",
    "\n",
    "Building histograms of found ORF length distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ORF length distribution analysis ===\")\n",
    "\n",
    "def plot_orf_length_distribution(orfs_list, title=\"ORF Length Distribution\"):\n",
    "    \"\"\"\n",
    "    Plots histogram of ORF length distribution\n",
    "    \"\"\"\n",
    "    if not orfs_list:\n",
    "        print(f\"No ORFs found for: {title}\")\n",
    "        return\n",
    "\n",
    "    orf_lengths = [orf['length'] for orf in orfs_list]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(orf_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"ORF length (nucleotides)\")\n",
    "    plt.ylabel(\"Number of ORFs\")\n",
    "    plt.yscale('log')  # Log scale for better visualization\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Statistics\n",
    "    min_length = min(orf_lengths)\n",
    "    max_length = max(orf_lengths)\n",
    "    avg_length = sum(orf_lengths) / len(orf_lengths)\n",
    "    \n",
    "    print(f\"Total number of ORFs: {len(orf_lengths):,}\")\n",
    "    print(f\"Shortest ORF: {min_length} bp\")\n",
    "    print(f\"Longest ORF: {max_length} bp\")\n",
    "    print(f\"Average ORF length: {avg_length:.1f} bp\")\n",
    "\n",
    "# Analyze length distributions\n",
    "plot_orf_length_distribution(orfs_plus, \"ORF Length Distribution (forward strand)\")\n",
    "plot_orf_length_distribution(orfs_minus, \"ORF Length Distribution (reverse strand)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5651ce9",
   "metadata": {},
   "source": [
    "## PART 10: EXTRACTING REFERENCE GENES FROM GFF\n",
    "\n",
    "Extracting real gene sequences for comparison with our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Extracting reference genes from GFF ===\")\n",
    "\n",
    "# Load BioPython if not available\n",
    "try:\n",
    "    from Bio import SeqIO\n",
    "except ImportError:\n",
    "    print(\"Installing BioPython...\")\n",
    "    !pip install biopython\n",
    "    from Bio import SeqIO\n",
    "\n",
    "import csv\n",
    "\n",
    "def extract_orfs_from_gff(gff_file, fasta_file):\n",
    "    \"\"\"\n",
    "    Extracts gene sequences from GFF annotation and FASTA file\n",
    "    \"\"\"\n",
    "    # Load sequences\n",
    "    seq_dict = SeqIO.to_dict(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "    orfs = []\n",
    "\n",
    "    with open(gff_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 9 or row[0].startswith('#') or row[2] != 'gene':\n",
    "                continue\n",
    "                \n",
    "            chrom = row[0]\n",
    "            start = int(row[3]) - 1  # Convert to 0-based coordinates\n",
    "            end = int(row[4])\n",
    "            strand = row[6]\n",
    "\n",
    "            # Extract sequence\n",
    "            sequence = seq_dict[chrom].seq[start:end]\n",
    "            if strand == '-':\n",
    "                continue  # For now analyze only forward strand\n",
    "                \n",
    "            orfs.append({\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'frame': (start) % 3,  # Simplified frame determination\n",
    "                'sequence': str(sequence),\n",
    "                'length': end - start\n",
    "            })\n",
    "\n",
    "    return orfs\n",
    "\n",
    "# Extract reference genes\n",
    "print(\"Extracting reference genes from annotation...\")\n",
    "gff_file = \"GCF_000005845.2_ASM584v2_genomic.gff\"\n",
    "fasta_file = \"GCF_000005845.2_ASM584v2_genomic.fna\"\n",
    "reference_orfs = extract_orfs_from_gff(gff_file, fasta_file)\n",
    "\n",
    "print(f\"Extracted {len(reference_orfs)} reference genes\")\n",
    "print(f\"Predicted {len(orfs_plus)} ORFs\")\n",
    "\n",
    "# Show example reference gene\n",
    "if reference_orfs:\n",
    "    print(f\"\\nExample reference gene:\")\n",
    "    ref_gene = reference_orfs[0]\n",
    "    print(f\"Position: {ref_gene['start']}-{ref_gene['end']}\")\n",
    "    print(f\"Length: {ref_gene['length']} bp\")\n",
    "    print(f\"Sequence: {ref_gene['sequence'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cf057",
   "metadata": {},
   "source": [
    "## PART 11: PREDICTION QUALITY EVALUATION\n",
    "\n",
    "For prediction quality evaluation we use standard metrics:\n",
    "\n",
    "- **True Positive (TP)** - correctly predicted genes\n",
    "- **False Positive (FP)** - falsely predicted genes (predicted but no gene exists)\n",
    "- **False Negative (FN)** - missed genes (gene exists but not predicted)\n",
    "\n",
    "**Metrics:**\n",
    "- **Precision** = TP / (TP + FP) - fraction of correct among predicted\n",
    "- **Recall** = TP / (TP + FN) - fraction found among all real\n",
    "- **F1-score** = 2 * (Precision * Recall) / (Precision + Recall) - harmonic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be70ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def match_orfs(predicted, truth, tolerance=0):\n",
    "    \"\"\"\n",
    "    Matches predicted ORFs with reference ones\n",
    "    \n",
    "    Args:\n",
    "        predicted: list of predicted ORFs\n",
    "        truth: list of reference ORFs\n",
    "        tolerance: allowable coordinate deviation\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (TP, FP, FN)\n",
    "    \"\"\"\n",
    "    pred_intervals = [(orf['start'], orf['end']) for orf in predicted]\n",
    "    true_intervals = [(orf['start'], orf['end']) for orf in truth]\n",
    "    \n",
    "    matched_true = set()\n",
    "    tp = 0  # True Positives\n",
    "    fp = 0  # False Positives\n",
    "\n",
    "    # Check each predicted ORF\n",
    "    for p_start, p_end in pred_intervals:\n",
    "        found_match = False\n",
    "        for idx, (t_start, t_end) in enumerate(true_intervals):\n",
    "            if idx in matched_true:\n",
    "                continue\n",
    "            \n",
    "            # Check coordinate match with tolerance\n",
    "            if (abs(p_start - t_start) <= tolerance and \n",
    "                abs(p_end - t_end) <= tolerance):\n",
    "                tp += 1\n",
    "                matched_true.add(idx)\n",
    "                found_match = True\n",
    "                break\n",
    "        \n",
    "        if not found_match:\n",
    "            fp += 1\n",
    "\n",
    "    fn = len(true_intervals) - len(matched_true)  # False Negatives\n",
    "    return tp, fp, fn\n",
    "\n",
    "def compute_metrics(tp, fp, fn):\n",
    "    \"\"\"Computes quality metrics\"\"\"\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    accuracy = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'TP': tp,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Precision': round(precision, 4),\n",
    "        'Recall': round(recall, 4),\n",
    "        'F1 Score': round(f1, 4),\n",
    "    }\n",
    "\n",
    "def evaluate_prediction(predicted_orfs, reference_orfs, tolerance=0):\n",
    "    \"\"\"Evaluates prediction quality and prints results\"\"\"\n",
    "    tp, fp, fn = match_orfs(predicted_orfs, reference_orfs, tolerance)\n",
    "    metrics = compute_metrics(tp, fp, fn)\n",
    "    \n",
    "    print(f\"Evaluation results (tolerance ¬±{tolerance} bp):\")\n",
    "    print(\"-\" * 50)\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric:12}: {value}\")\n",
    "    \n",
    "    print(f\"\\nInterpretation:\")\n",
    "    print(f\"- From {len(reference_orfs)} real genes found {tp} ({metrics['Recall']*100:.1f}%)\")\n",
    "    print(f\"- From {len(predicted_orfs)} predicted {tp} correct ({metrics['Precision']*100:.1f}%)\")\n",
    "    print(f\"- Missed {fn} genes\")\n",
    "    print(f\"- Falsely predicted {fp} genes\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate basic prediction\n",
    "print(\"Evaluating basic ORF finding algorithm:\")\n",
    "metrics_base = evaluate_prediction(orfs_plus, reference_orfs, tolerance=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ddfc1f",
   "metadata": {},
   "source": [
    "## PART 12: FILTERING ORFs BY LENGTH\n",
    "\n",
    "Most found ORFs are very short and unlikely to code for proteins. Let's apply a minimum length filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc33139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Filtering ORFs by length ===\")\n",
    "print(\"Most found ORFs are very short and unlikely to code for proteins\")\n",
    "print(\"Applying filter: keep only ORFs longer than 150 nucleotides (50 amino acids)\")\n",
    "\n",
    "# Filter short ORFs\n",
    "min_length = 150  # nucleotides\n",
    "orfs_filtered = [orf for orf in orfs_plus if orf[\"length\"] >= min_length]\n",
    "\n",
    "print(f\"Before filtering: {len(orfs_plus):,} ORFs\")\n",
    "print(f\"After filtering: {len(orfs_filtered):,} ORFs\")\n",
    "print(f\"Filtered out: {len(orfs_plus) - len(orfs_filtered):,} short ORFs\")\n",
    "\n",
    "# Evaluation after filtering\n",
    "print(\"\\nEvaluation after length filtering:\")\n",
    "metrics_filtered = evaluate_prediction(orfs_filtered, reference_orfs, tolerance=0)\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\nResults comparison:\")\n",
    "print(f\"{'Metric':<12} {'Basic':<10} {'Filtered':<12} {'Change'}\")\n",
    "print(\"-\" * 50)\n",
    "for metric in ['Precision', 'Recall', 'F1 Score']:\n",
    "    base_val = metrics_base[metric]\n",
    "    filt_val = metrics_filtered[metric]\n",
    "    change = filt_val - base_val\n",
    "    change_str = f\"{change:+.3f}\"\n",
    "    print(f\"{metric:<12} {base_val:<10.3f} {filt_val:<12.3f} {change_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e035b7",
   "metadata": {},
   "source": [
    "## PART 13: PREDICTION ERROR ANALYSIS\n",
    "\n",
    "Detailed analysis of where our algorithm makes mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Prediction error analysis ===\")\n",
    "\n",
    "def analyze_prediction_errors(predicted, reference, tolerance=0):\n",
    "    \"\"\"\n",
    "    Detailed analysis of where our algorithm makes mistakes\n",
    "    \"\"\"\n",
    "    # Classify each predicted ORF\n",
    "    matched_ref = set()\n",
    "    classified_pred = []\n",
    "    \n",
    "    for pred_orf in predicted:\n",
    "        match_type = 'FP'  # Default False Positive\n",
    "        \n",
    "        for idx, ref_orf in enumerate(reference):\n",
    "            if idx in matched_ref:\n",
    "                continue\n",
    "                \n",
    "            # Check different types of matches\n",
    "            start_match = abs(pred_orf['start'] - ref_orf['start']) <= tolerance\n",
    "            end_match = abs(pred_orf['end'] - ref_orf['end']) <= tolerance\n",
    "            \n",
    "            if start_match and end_match:\n",
    "                match_type = 'TP-full'  # Full match\n",
    "                matched_ref.add(idx)\n",
    "                break\n",
    "            elif start_match:\n",
    "                match_type = 'TP-start'  # Only start matches\n",
    "                matched_ref.add(idx)\n",
    "                break\n",
    "            elif end_match:\n",
    "                match_type = 'TP-end'  # Only end matches\n",
    "                matched_ref.add(idx)\n",
    "                break\n",
    "        \n",
    "        classified_pred.append({**pred_orf, 'type': match_type})\n",
    "    \n",
    "    # Classify reference ORFs\n",
    "    classified_ref = []\n",
    "    for idx, ref_orf in enumerate(reference):\n",
    "        ref_type = 'FN' if idx not in matched_ref else 'TP'\n",
    "        classified_ref.append({**ref_orf, 'type': ref_type})\n",
    "    \n",
    "    return classified_pred, classified_ref\n",
    "\n",
    "# Analyze errors\n",
    "print(\"Classifying predicted ORFs...\")\n",
    "pred_classified, ref_classified = analyze_prediction_errors(\n",
    "    orfs_filtered, reference_orfs, tolerance=0\n",
    ")\n",
    "\n",
    "# Count match types\n",
    "from collections import Counter\n",
    "pred_types = Counter([orf['type'] for orf in pred_classified])\n",
    "\n",
    "print(\"Classification results:\")\n",
    "print(f\"  Full matches (TP-full):       {pred_types['TP-full']}\")\n",
    "print(f\"  Start matches:                {pred_types['TP-start']}\")\n",
    "print(f\"  End matches:                  {pred_types['TP-end']}\")\n",
    "print(f\"  False predictions (FP):       {pred_types['FP']}\")\n",
    "\n",
    "fn_count = len([orf for orf in ref_classified if orf['type'] == 'FN'])\n",
    "print(f\"  Missed genes (FN):            {fn_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529d1af",
   "metadata": {},
   "source": [
    "## PART 14: GC CONTENT ANALYSIS\n",
    "\n",
    "GC content can help distinguish real genes from random ORFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23259dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== GC content analysis ===\")\n",
    "print(\"GC content can help distinguish real genes from random ORFs\")\n",
    "\n",
    "def gc_content(sequence):\n",
    "    \"\"\"Calculates GC content of sequence (in percent)\"\"\"\n",
    "    sequence = sequence.upper()\n",
    "    gc_count = sequence.count('G') + sequence.count('C')\n",
    "    return 100 * gc_count / len(sequence) if len(sequence) > 0 else 0\n",
    "\n",
    "def compare_gc_content(predicted_classified):\n",
    "    \"\"\"Compares GC content of correct and false predictions\"\"\"\n",
    "    tp_gc = []\n",
    "    fp_gc = []\n",
    "    \n",
    "    for orf in predicted_classified:\n",
    "        gc = gc_content(orf['sequence'])\n",
    "        if orf['type'] == 'TP-full':\n",
    "            tp_gc.append(gc)\n",
    "        elif orf['type'] == 'FP':\n",
    "            fp_gc.append(gc)\n",
    "    \n",
    "    if tp_gc and fp_gc:\n",
    "        avg_tp = sum(tp_gc) / len(tp_gc)\n",
    "        avg_fp = sum(fp_gc) / len(fp_gc)\n",
    "        \n",
    "        print(f\"Average GC content:\")\n",
    "        print(f\"  Correct predictions: {avg_tp:.1f}% (n={len(tp_gc)})\")\n",
    "        print(f\"  False predictions:   {avg_fp:.1f}% (n={len(fp_gc)})\")\n",
    "        \n",
    "        # Plot histogram\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(tp_gc, bins=20, alpha=0.7, label='Correct (TP)', density=True)\n",
    "        plt.hist(fp_gc, bins=20, alpha=0.7, label='False (FP)', density=True)\n",
    "        plt.xlabel('GC content (%)')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title('GC Content Distribution: Correct vs False Predictions')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return avg_tp, avg_fp\n",
    "    else:\n",
    "        print(\"Insufficient data for GC content analysis\")\n",
    "        return None, None\n",
    "\n",
    "# Analyze GC content\n",
    "tp_gc, fp_gc = compare_gc_content(pred_classified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e878408",
   "metadata": {},
   "source": [
    "## CONCLUSION\n",
    "\n",
    "The analysis results show the importance of a comprehensive approach to gene prediction and the necessity of using multiple criteria to distinguish real genes from random open reading frames.\n",
    "\n",
    "### Key findings:\n",
    "1. **High level of false predictions** - most ORFs are not genes\n",
    "2. **Simple search by start/stop codons is insufficient**\n",
    "3. **Additional filters needed** (GC content, Shine-Dalgarno, codon bias)\n",
    "\n",
    "### Possible improvements:\n",
    "1. Search for Shine-Dalgarno sequences before ATG\n",
    "2. Codon bias analysis\n",
    "3. Machine learning on sequence features\n",
    "4. Comparative genomics\n",
    "5. Expression analysis (RNA-seq data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a253233",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "E.coli genome analysis results:\n",
    "\n",
    "üìä GENOME STATISTICS:\n",
    "  ‚Ä¢ Genome length: {len(genome_sequence):,} nucleotides\n",
    "  ‚Ä¢ Reference genes: {len(reference_orfs)}\n",
    "  ‚Ä¢ Found potential ORFs: {len(orfs_plus):,}\n",
    "  ‚Ä¢ After length filtering: {len(orfs_filtered):,}\n",
    "\n",
    "üéØ PREDICTION QUALITY:\n",
    "  ‚Ä¢ Precision: {metrics_filtered['Precision']:.1%}\n",
    "  ‚Ä¢ Recall: {metrics_filtered['Recall']:.1%}\n",
    "  ‚Ä¢ F1-score: {metrics_filtered['F1 Score']:.3f}\n",
    "\n",
    "üîç MAIN PROBLEMS:\n",
    "  1. High level of false predictions - most ORFs are not genes\n",
    "  2. Simple start/stop codon search is insufficient\n",
    "  3. Additional filters needed (GC content, Shine-Dalgarno, codon bias)\n",
    "\n",
    "üí° POSSIBLE IMPROVEMENTS:\n",
    "  1. Search for Shine-Dalgarno sequences before ATG\n",
    "  2. Codon bias analysis\n",
    "  3. Machine learning on sequence features\n",
    "  4. Comparative genomics\n",
    "  5. Expression analysis (RNA-seq data)\n",
    "\n",
    "This analysis shows the importance of a comprehensive approach to gene prediction\n",
    "and the necessity of using multiple criteria to distinguish real genes\n",
    "from random open reading frames.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nAdjust filtering parameters and try other approaches!\")\n",
    "print(\"Good luck studying bioinformatics! üß¨\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
